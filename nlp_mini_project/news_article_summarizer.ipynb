{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXHpVUp7H7N1z0JiSzBRPi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharva0300/BE-8th-Semester/blob/main/nlp_mini_project/news_article_summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install newspaper3k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avxQrojkiWRP",
        "outputId": "2a72a2ac-f125-4a7a-94b1-9f2b850c5f59"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (5.1.2)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2024.2.2)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.0.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = input(\"Enter the url of the news article webpage : \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snwySMStv5Ym",
        "outputId": "df0630ab-f92a-4593-b06a-c3b40205a51f"
      },
      "execution_count": 301,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the url of the news article webpage : \n",
            "https://economictimes.indiatimes.com/markets/cryptocurrency/bitcoin-tops-70000-again-after-slumping-on-us-etf-outflows/articleshow/108773929.cms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain the news paper\n",
        "from newspaper import Article\n",
        "\n",
        "def extract_article(url):\n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "    return article.text\n",
        "\n",
        "article_text = extract_article(url)\n",
        "print(article_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIuIiMIkiaov",
        "outputId": "74de4431-536b-4557-d150-162a9a3b22cc"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "(You can now subscribe to our\n",
            "\n",
            "(You can now subscribe to our ETMarkets WhatsApp channel\n",
            "\n",
            "New York: Bitcoin enthusiasts appear to be shrugging off last week's outflows from US exchange-traded funds, with the largest cryptocurrency briefly climbing back above $70,000 again.Most digital assets were higher Monday, with Bitcoin gaining as much as 5.8% to $70,014. That's the first time the token has been above $70,000 in more than a week. Ether was up around 5%, while Solana and Dogecoin were both more than 4% higher.Almost $900 million was pulled from those ETFs last week, reflecting continual outflows from the Grayscale Bitcoin Trust as well as a moderation in subscriptions for offerings from BlackRock Inc. and Fidelity Investment. The group of 10 funds saw one of the worst weeks of the year since they were launched in January.\"Even though ETF inflows have hit a drag, order books are loaded on the bid side around the 60k area, showing that the market is eager to buy the dip,\" said Nathanael Cohen, co-founder at digital-asset hedge fund INDIGO Fund.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nofwpYGkhyAV",
        "outputId": "d98bde48-61f6-4cb7-d37c-a7634caf75cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text into sentences\n",
        "    sentences = sent_tokenize(text)\n",
        "\n",
        "    # Tokenize each sentence into words, remove stopwords, and perform stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    preprocessed_sentences = []\n",
        "    for sentence in sentences:\n",
        "        words = word_tokenize(sentence.lower())\n",
        "        words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
        "        preprocessed_sentences.append(\" \".join(words))\n",
        "\n",
        "    return preprocessed_sentences\n",
        "\n",
        "def textrank_summarizer(text, num_sentences=3):\n",
        "    # Preprocess the text\n",
        "    preprocessed_sentences = preprocess_text(text)\n",
        "\n",
        "    # Create TF-IDF matrix\n",
        "    tfidf = TfidfVectorizer().fit_transform(preprocessed_sentences)\n",
        "\n",
        "    # Calculate similarity matrix\n",
        "    similarity_matrix = cosine_similarity(tfidf, tfidf)\n",
        "\n",
        "    # Create graph using similarity matrix\n",
        "    graph = nx.from_numpy_array(similarity_matrix)\n",
        "\n",
        "    # Calculate PageRank scores\n",
        "    scores = nx.pagerank(graph)\n",
        "\n",
        "    # Sort sentences by PageRank scores\n",
        "    ranked_sentences = sorted(((scores[i], sentence) for i, sentence in enumerate(preprocessed_sentences)), reverse=True)\n",
        "\n",
        "    # Get top N sentences for summary\n",
        "    summary_sentences = [sentence for score, sentence in ranked_sentences[:num_sentences]]\n",
        "\n",
        "    # Reorder the summary sentences based on their order in the original text\n",
        "    summary = \" \".join([preprocessed_sentences[preprocessed_sentences.index(sent)] for sent in summary_sentences])\n",
        "\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of Textrank algorithm\n",
        "\n",
        "summary = textrank_summarizer(article_text)\n",
        "summary_list = summary.split(' ')\n",
        "output_text = \"\"\n",
        "for i in range(len(summary_list)) :\n",
        "  if(i%30==0 and i!=0 ) :\n",
        "    print('\\n')\n",
        "    output_text += \"\\n\"\n",
        "  else :\n",
        "    output_text += summary_list[i] + \" \"\n",
        "    print(summary_list[i] , end = \" \")\n",
        "\n",
        "textrank_output = output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYHex63diD69",
        "outputId": "06f6f26d-9120-4ac1-fda5-a853038e1169"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "( subscrib ( subscrib etmarket whatsapp channel new york : bitcoin enthusiast appear shrug last week 's outflow us exchange-trad fund , largest cryptocurr briefli climb back $ 70,000 again.most \n",
            "\n",
            "asset higher monday , bitcoin gain much 5.8 % $ 70,014 . 's first time token $ 70,000 week . ether around 5 % , solana dogecoin 4 % \n",
            "\n",
            "$ 900 million pull etf last week , reflect continu outflow grayscal bitcoin trust well moder subscript offer blackrock inc. fidel invest . "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sumy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9jWJXWMkEmV",
        "outputId": "e9796b22-17ec-4a38-d9b7-255d26800c73"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sumy in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: docopt<0.7,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.6.2)\n",
            "Requirement already satisfied: breadability>=0.1.20 in /usr/local/lib/python3.10/dist-packages (from sumy) (0.1.20)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from sumy) (2.31.0)\n",
            "Requirement already satisfied: pycountry>=18.2.23 in /usr/local/lib/python3.10/dist-packages (from sumy) (23.12.11)\n",
            "Requirement already satisfied: nltk>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from sumy) (3.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n",
            "Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.10/dist-packages (from breadability>=0.1.20->sumy) (4.9.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.0.2->sumy) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.7.0->sumy) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TUk9i_z5mGkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sumy.parsers.plaintext import PlaintextParser\n",
        "from sumy.nlp.tokenizers import Tokenizer\n",
        "from sumy.summarizers.lex_rank import LexRankSummarizer\n",
        "\n",
        "# Function to summarize a news article using LexRank\n",
        "def summarize_news_article(text, language='english', sentences_count=3):\n",
        "    parser = PlaintextParser.from_string(text, Tokenizer(language))\n",
        "    summarizer = LexRankSummarizer()\n",
        "\n",
        "    # Summarize the article\n",
        "    summary = summarizer(parser.document, sentences_count)\n",
        "    summary_text = ' '.join([str(sentence) for sentence in summary])\n",
        "\n",
        "    return summary_text\n",
        "\n",
        "# Summarize the news article\n",
        "summary = summarize_news_article(article_text)\n",
        "summary_list = summary.split(' ')\n",
        "output_text = \"\"\n",
        "for i in range(len(summary_list)) :\n",
        "  if(i%30==0 and i!=0 ) :\n",
        "    print('\\n')\n",
        "    output_text += \"\\n\"\n",
        "  else :\n",
        "    output_text += summary_list[i] + \" \"\n",
        "    print(summary_list[i] , end = \" \")\n",
        "\n",
        "lexrank_output = output_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njbxG08dk5BD",
        "outputId": "f71a6eec-10cf-485e-c33f-5e2576a07549"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(You can now subscribe to our (You can now subscribe to our ETMarkets WhatsApp channel New York: Bitcoin enthusiasts appear to be shrugging off last week's outflows from US exchange-traded \n",
            "\n",
            "with the largest cryptocurrency briefly climbing back above $70,000 again.Most digital assets were higher Monday, with Bitcoin gaining as much as 5.8% to $70,014. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoCujn49oG38",
        "outputId": "f959faa5-f2e4-47da-eed3-0faf5d43328b"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the summarization pipeline\n",
        "#summarizer = pipeline(\"summarization\")"
      ],
      "metadata": {
        "id": "0SsUZLVzrnuM"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formatting the text\n",
        "import textwrap\n",
        "formatted_text = textwrap.fill(article_text, width=80)\n",
        "formatted_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "PS0omu4ttjBZ",
        "outputId": "8cc138e3-ce43-44b1-826d-978253a03d29"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'    (You can now subscribe to our  (You can now subscribe to our ETMarkets\\nWhatsApp channel  New York: Bitcoin enthusiasts appear to be shrugging off last\\nweek\\'s outflows from US exchange-traded funds, with the largest cryptocurrency\\nbriefly climbing back above $70,000 again.Most digital assets were higher\\nMonday, with Bitcoin gaining as much as 5.8% to $70,014. That\\'s the first time\\nthe token has been above $70,000 in more than a week. Ether was up around 5%,\\nwhile Solana and Dogecoin were both more than 4% higher.Almost $900 million was\\npulled from those ETFs last week, reflecting continual outflows from the\\nGrayscale Bitcoin Trust as well as a moderation in subscriptions for offerings\\nfrom BlackRock Inc. and Fidelity Investment. The group of 10 funds saw one of\\nthe worst weeks of the year since they were launched in January.\"Even though ETF\\ninflows have hit a drag, order books are loaded on the bid side around the 60k\\narea, showing that the market is eager to buy the dip,\" said Nathanael Cohen,\\nco-founder at digital-asset hedge fund INDIGO Fund.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "import textwrap\n",
        "\n",
        "# Load the tokenizer and model\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
        "\n",
        "# Wrap the formatted text to 1024 tokens per input (maximum input length for BART)\n",
        "wrapped_text = textwrap.fill(article_text, width=1024)\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(wrapped_text, return_tensors='pt', max_length=1024, truncation=True)\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=30, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "th5ydvMGrFK5"
      },
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of BART Transformer\n",
        "\n",
        "summary_list = summary.split(' ')\n",
        "output_text = \"\"\n",
        "\n",
        "for i in range(len(summary_list)) :\n",
        "  if(i%30==0 and i!=0 ) :\n",
        "    print('\\n')\n",
        "    output_text += \"\\n\"\n",
        "  else :\n",
        "    output_text += summary_list[i] + \" \"\n",
        "    print(summary_list[i] , end = \" \")\n",
        "\n",
        "bart_output = output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bt80QqVqtND",
        "outputId": "764e4bb2-9096-4b26-ee7c-79c679b1a3a2"
      },
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most digital assets were higher Monday, with Bitcoin gaining as much as 5.8%. Ether was up around 5%, while Solana and Dogecoin were both more than 4% higher. Almost $900 \n",
            "\n",
            "was pulled from those ETFs last week. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Load pre-trained T5 model and tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer.encode(\"summarize: \" + article_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# Generate the summary\n",
        "summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDF-_TRCvCDE",
        "outputId": "2e6fd95f-14dc-469d-e86d-1e62a511b440"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output of T5 Transformer\n",
        "\n",
        "summary_list = summary.split(' ')\n",
        "output_text = \"\"\n",
        "for i in range(len(summary_list)) :\n",
        "  if(i%30==0 and i!=0 ) :\n",
        "    print('\\n')\n",
        "    output_text += \"\\n\"\n",
        "  else :\n",
        "    output_text += summary_list[i] + \" \"\n",
        "    print(summary_list[i] , end = \" \")\n",
        "\n",
        "t5_output = output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IAaC39uvZwl",
        "outputId": "c4adcf39-eab7-4e7a-9e7c-3ebeb9fc6b51"
      },
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the largest cryptocurrency has been above $70,000 in more than a week. it's the first time the token has been above $70,000 in more than a week. it's the first \n",
            "\n",
            "the token has been above $70,000 in more than a week. "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install reportlab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxyFs0R9xcwo",
        "outputId": "eef6f872-f108-4a0d-c020-081e3d8db677"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pdf and store the outputs in the pdf file\n",
        "\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from google.colab import files\n",
        "\n",
        "# Create a PDF file\n",
        "def create_pdf(file_name, text):\n",
        "    custom_page_height = 1600  # Custom page height in points\n",
        "    c = canvas.Canvas(file_name,  pagesize=(letter[0], custom_page_height))\n",
        "    lines = text.split('\\n')\n",
        "    y_position = 1550  # Starting vertical position\n",
        "    line_height = 12  # Height of each line\n",
        "    max_width = 500  # Maximum width of the text\n",
        "\n",
        "    for line in lines:\n",
        "        # Calculate the height of the text\n",
        "        text_width = c.stringWidth(line, \"Helvetica\", 12)\n",
        "\n",
        "        # If the text exceeds the maximum width, create a new line\n",
        "        if text_width > max_width:\n",
        "            parts = [line[i:i+100] for i in range(0, len(line), 100)]  # Split line into parts\n",
        "            for part in parts:\n",
        "                c.drawString(20, y_position, part)\n",
        "                y_position -= line_height  # Move to the next line\n",
        "        else:\n",
        "            c.drawString(20, y_position, line)\n",
        "            y_position -= line_height  # Move to the next line\n",
        "\n",
        "    c.save()\n",
        "\n",
        "\n",
        "# Text to write in the PDF\n",
        "text = \"\"\n",
        "text = \"                                                                News Summarizer Report\\n\\n\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += \"Article\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += article_text\n",
        "text += \"\\n\\n\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += \"TextRank Algorithm Output\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += textrank_output\n",
        "text += \"\\n\\n\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += \"LexRank Algorithm Output\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += lexrank_output\n",
        "text += \"\\n\\n\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += \"BART Output\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += bart_output\n",
        "text += \"\\n\\n\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += \"T5 Output\\n\"\n",
        "text += \"------------------------------------------------------------------------------------------------------------------------\\n\"\n",
        "text += t5_output\n",
        "text += \"\\n\\n\\n\"\n",
        "\n",
        "# Create and save the PDF file\n",
        "file_name = \"News_Summarizer_Report.pdf\"\n",
        "create_pdf(file_name, text)\n",
        "\n",
        "# Download the PDF file\n",
        "files.download(file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Lq2rUrAvvim-",
        "outputId": "8c3d099f-53b8-41ae-dcf5-d1d707164377"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_59a13e34-9bbb-4a3f-ae59-e3484c8782c8\", \"News_Summarizer_Report.pdf\", 2933)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdjInrtUyv73"
      },
      "execution_count": 315,
      "outputs": []
    }
  ]
}